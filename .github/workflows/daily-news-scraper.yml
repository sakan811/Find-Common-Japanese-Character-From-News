name: Daily News Scraper

on:
  schedule:
    - cron: '0 8,13,18 * * *'
  workflow_dispatch:

permissions:
  contents: 'read'
  id-token: 'write'

jobs:
  build:

    runs-on: windows-latest
    strategy:
      matrix:
        python-version: ["3.12" ]

    steps:
    - uses: actions/checkout@v4

    - name: Cache pip dependencies
      id: cache
      uses: actions/cache@v4
      with:
        path: ~\AppData\Local\pip\Cache
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        python -m pip install pytest
        if (Test-Path requirements.txt) { python -m pip install -r requirements.txt }

    - name: Scrape News
      run: |
        python automated_news_scraper.py

    - id: 'auth'
      uses: 'google-github-actions/auth@v2'
      with:
        credentials_json: ${{ secrets.KEY_JSON }}

    - id: 'upload-file'
      uses: 'google-github-actions/upload-cloud-storage@v2'
      with:
        path: './'
        destination: 'gcp_japan_news'
        gzip: false
        headers: |-
          content-type: application/octet-stream
        glob: '**/*.parquet'


